ğŸ‘ï¸ Agent Profile: vision_agent â€“ cncpick2

This document defines the role, behavior, and output of the vision_agent, which performs object detection from RGBD inputs and sends actionable metadata to the system.

â¸»

ğŸ§  Agent Overview
	â€¢	Monitors simulated or real RGB + depth camera inputs
	â€¢	Performs object detection (e.g., YOLO on green objects)
	â€¢	Infers lane, area, and object height
	â€¢	Emits object_detected messages for scoring

Example Name:

vision_agent


â¸»

ğŸ“‚ Responsibilities
	1.	Read frames from camera or sim feed
	2.	Run object detection (YOLO or equivalent)
	3.	Use pixel position to determine conveyor lane
	4.	Use depth map to estimate object Z height (mm)
	5.	Compute area in pixels for quality scoring
	6.	Publish detection metadata for each object

â¸»

ğŸ“¤ Published Events

object_detected

{
  "event": "object_detected",
  "agent": "vision_agent",
  "timestamp": "...",
  "payload": {
    "object_id": "uuid",
    "lane": 2,
    "class": "green_target",
    "height_mm": 32.1,
    "area_px": 3088
  }
}


â¸»

ğŸ§© Supporting Functions

Lane Mapping
	â€¢	Maps object pixel x to logical lane (0â€“3)
	â€¢	Uses calibrated camera-lane map file or lane_mapper utility

Height Estimation
	â€¢	Uses depth map (Z) for objectâ€™s top surface
	â€¢	May average over center region to smooth out noise

Detection Backend
	â€¢	Configurable: can use pretrained YOLO, mock boxes, or OpenCV blob detector
	â€¢	Simulation mode injects known detections for test objects

â¸»

âš™ï¸ Configuration Options

vision_agent:
  input_source: "rgbd_stream"  # or "sim"
  model: "yolov5"
  lane_map: "config/lane_mapping.json"
  min_area_px: 2500
  max_objects: 10


â¸»

ğŸ§ª Simulation Mode
	â€¢	Loads frames or synthetic detections from simulator_agent
	â€¢	Matches timing of real detection pipeline (frame rate, delay)
	â€¢	Allows deterministic tests with known object sets

â¸»

ğŸ§¾ Logging

Every detection is sent as a PUB message and also consumed by:
	â€¢	scoring_agent
	â€¢	data_logging_agent
	â€¢	post_pick_monitor_agent

â¸»

ğŸ” Sanity Test Checks
	â€¢	Must emit object_detected after every object_spawned
	â€¢	Payload must include: lane, area, height, object_id

â¸»

ğŸ“Œ Summary
	â€¢	Translates visual input into actionable metadata
	â€¢	Allows scoring + motion systems to operate agnostic to camera format
	â€¢	Central to accurate pickup and lane alignment