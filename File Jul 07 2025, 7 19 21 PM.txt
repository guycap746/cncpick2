âš™ï¸ Test Automation Frameworks â€“ cncpick2

This document outlines strategies and utilities for automated testing of the cncpick2 system, covering both sanity-level and advanced behavioral testing across agents.

â¸»

ğŸ¯ Objectives
	â€¢	Catch regressions early in simulation and hardware logic
	â€¢	Validate agent roles, message structure, and timing
	â€¢	Enable repeatable, structured dev workflow

â¸»

ğŸ§ª Test Types

Type	Description
Sanity Tests	Step-by-step verification of object flow
Integration Tests	Verify agents working together as expected
Load Tests	Simulate high-throughput scenarios
Chaos Tests	Inject faults to verify resilience & safety
Regression Tests	Replay old logs to confirm logic stability


â¸»

ğŸ§° Tools
	â€¢	test_runner.py: Main harness
	â€¢	assert_helpers.py: Shared logic for hook validation
	â€¢	sample_logs/: Fixture examples and comparison sets
	â€¢	Optional: pytest integration for coverage reporting

â¸»

ğŸ§  Hooks & Validation

Each test phase uses agent-logged events to assert proper state:

assert event['agent'] == 'scoring_agent'
assert event['event'] == 'object_assigned'

Hooks include:
	â€¢	After object spawn
	â€¢	After YOLO detection
	â€¢	After scoring decision
	â€¢	After motion pickup/drop

â¸»

ğŸ” Test Profiles

Profile	Purpose
standard_throughput	Mixed-object scenario for benchmarks
lane_conflict	Multiple items in one lane
timeout_fallbacks	Missed pickups and error paths


â¸»

ğŸ“Œ Summary

The testing framework ensures that development across agents remains coordinated, auditable, and safe for expansion into real hardware. All tests can be run continuously during CI, or interactively by developers in simulation.